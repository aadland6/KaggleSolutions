{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from collections import Counter \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.metrics import classification_report as report \n",
    "from sklearn.model_selection import train_test_split as split, cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initalize the data \n",
    "with open(\"train.json\", \"rb\") as t:\n",
    "    train_json = json.load(t)\n",
    "raw_train = pd.DataFrame.from_dict(train_json)\n",
    "raw_train.head()\n",
    "# split the dataframe into two in order to test how well our models will generalize to new data \n",
    "train, test = split(raw_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest text representation is a \"bag of words\" model where the order of words in a document is irrelevant. While this doesn't work for all documents, it is a good starting point for most NLP projects. In this project in particular, it is a good assumption as the ingredients are nouns and word dependencies (e.g., parts of speech) do not matter. \n",
    "\n",
    "For this first attempt, we'll generate a simple term document matrix where each term is a column in the matrix and each row is a recipe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.74      0.54      0.62       115\n",
      "     british       0.59      0.38      0.46       194\n",
      "cajun_creole       0.81      0.69      0.74       371\n",
      "     chinese       0.80      0.82      0.81       677\n",
      "    filipino       0.69      0.57      0.63       174\n",
      "      french       0.62      0.61      0.61       657\n",
      "       greek       0.82      0.67      0.74       295\n",
      "      indian       0.84      0.89      0.86       780\n",
      "       irish       0.71      0.44      0.54       192\n",
      "     italian       0.77      0.89      0.83      1928\n",
      "    jamaican       0.79      0.60      0.68       129\n",
      "    japanese       0.80      0.68      0.73       373\n",
      "      korean       0.88      0.74      0.80       223\n",
      "     mexican       0.89      0.91      0.90      1625\n",
      "    moroccan       0.80      0.77      0.78       192\n",
      "     russian       0.65      0.37      0.47       116\n",
      " southern_us       0.66      0.82      0.73      1063\n",
      "     spanish       0.66      0.44      0.52       265\n",
      "        thai       0.74      0.74      0.74       353\n",
      "  vietnamese       0.70      0.51      0.59       222\n",
      "\n",
      " avg / total       0.77      0.77      0.76      9944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def fit_count_vectorizer(train, test):\n",
    "    \"\"\"Initalizes a simple count vectorizer \n",
    "    \"\"\"\n",
    "    count_vectorizer =  CountVectorizer(tokenizer = lambda doc: doc, \n",
    "                                       lowercase=False)\n",
    "    count_vectorizer.fit(train[\"ingredients\"])\n",
    "    train_matrix = count_vectorizer.transform(train[\"ingredients\"])\n",
    "    test_matrix = count_vectorizer.transform(test[\"ingredients\"])\n",
    "    return (train_matrix, train[\"cuisine\"]), (test_matrix, test[\"cuisine\"])\n",
    "\n",
    "train_count, test_count = fit_count_vectorizer(train, test)\n",
    "lr_model = LogisticRegression().fit(train_count[0], train_count[1])\n",
    "lr_predictions = lr_model.predict(test_count[0])\n",
    "lr_report = report(test_count[1], lr_predictions)\n",
    "print(lr_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The count vectorizer does not control for the frequency of common words. In longer documents or ones that resemble natural language more, it is likely that some words (e.g., \"I\", \"am\", \"be\", \"was\") will be repeated often. \n",
    "\n",
    "One way to control for this and to identify key words in a text (locally frequent, globally infrequent) is Term Frequency, Inverse Document Frequency (TF-IDF) weighting. \n",
    "\n",
    "Term frequency is how often a word appears in a particular document. For example, \"The red dog jumped over the red wagon\" would yield a TF score of: \n",
    "\n",
    "{'The': 1,\n",
    "'dog': 1,\n",
    "'jumped': 1,\n",
    "'over': 1,\n",
    "'red': 2,\n",
    "'the': 1,\n",
    "'wagon': 1}\n",
    "\n",
    "Inverse Document Frequency (IDF) takes the log of the number of documents in a corpus versus divided by the number of documents a particular term appears in. \n",
    "\n",
    "In python this would read as:\n",
    "def idf(word, corpus):\n",
    "    return math.log(len(corpus) / (1 + sum([1 for _ in corpus if word in _ ])))\n",
    "    \n",
    "The final calculation is just tf * idf \n",
    "You can read more up on TF-IDF on the relevant Wikipedia Article: https://en.wikipedia.org/wiki/Tf%E2%80%93idf\n",
    "\n",
    "Sklearn implements a tf-idf vectorizer similar to the CountVectorizer where each cell is weighted by tf-idf rather than just the counts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.81      0.37      0.51       115\n",
      "     british       0.60      0.29      0.39       194\n",
      "cajun_creole       0.81      0.65      0.72       371\n",
      "     chinese       0.79      0.86      0.82       677\n",
      "    filipino       0.76      0.53      0.62       174\n",
      "      french       0.57      0.58      0.58       657\n",
      "       greek       0.86      0.61      0.72       295\n",
      "      indian       0.83      0.90      0.87       780\n",
      "       irish       0.72      0.31      0.43       192\n",
      "     italian       0.73      0.90      0.81      1928\n",
      "    jamaican       0.84      0.53      0.65       129\n",
      "    japanese       0.85      0.64      0.73       373\n",
      "      korean       0.89      0.67      0.77       223\n",
      "     mexican       0.87      0.91      0.89      1625\n",
      "    moroccan       0.85      0.72      0.78       192\n",
      "     russian       0.69      0.27      0.39       116\n",
      " southern_us       0.62      0.81      0.70      1063\n",
      "     spanish       0.69      0.36      0.47       265\n",
      "        thai       0.75      0.76      0.75       353\n",
      "  vietnamese       0.75      0.47      0.58       222\n",
      "\n",
      " avg / total       0.76      0.76      0.75      9944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def fit_tfidf_vectorizer(train, test):\n",
    "    \"\"\"Initalizes a tf-idf vectorizer \n",
    "    \"\"\"\n",
    "    tfidf_vectorizer =  TfidfVectorizer(tokenizer = lambda doc: doc, \n",
    "                                       lowercase=False)\n",
    "    tfidf_vectorizer.fit(train[\"ingredients\"])\n",
    "    train_matrix = tfidf_vectorizer.transform(train[\"ingredients\"])\n",
    "    test_matrix = tfidf_vectorizer.transform(test[\"ingredients\"])\n",
    "    return (train_matrix, train[\"cuisine\"]), (test_matrix, test[\"cuisine\"])\n",
    "\n",
    "train_tfidf, test_tfidf = fit_tfidf_vectorizer(train, test)\n",
    "lr_tfidf = LogisticRegression().fit(train_tfidf[0], train_tfidf[1])\n",
    "lr_predictions_tfidf = lr_tfidf.predict(test_tfidf[0])\n",
    "lr_report_tfidf = report(test_tfidf[1], lr_predictions_tfidf)\n",
    "print(lr_report_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the TF-IDF weighting did not improve our model predictions. This makes sense given our data set has individual words (ingredients) that are not repeated within a recipe. This means the TF for each document (recipe) is always 1. \n",
    "\n",
    "In longer documents, TF-IDF is good starting point. In particular, if your analysis involves calculating the similarity between documents, TF-IDF is an important preprocessing step as common words will swamp the similarity between two different documents. \n",
    "\n",
    "In addition to TF-IDF weighting, there are other preprocessing steps that are common in text mining and could be beneficial with this dataset. In particular, string lemmatization may reduce some of the dimensionality in the dataset. Lemmatization reduces words to their common root e.g., \"am\", \"are\", \"is\" all map to \"be.\"\n",
    "\n",
    "Lemmatization is similar to stemming in terms of reducing words to their common root. It has the advantage of being more readable than word stemming but may be slower as a good lemmatizer will rely on Part of Speech tagging. In this dataset, we can treat all of the ingredients as nouns and avoid any part of speech tagging. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_lemmatizer(recipes):\n",
    "    \"\"\"Lemmatizes the individual ingredients and regroups them based on \n",
    "    \"\"\"\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    cleaned_recipes = []\n",
    "    for recipe in recipes:\n",
    "        cleaned_recipe = []\n",
    "        for ingredient in recipe:\n",
    "            cleaned_ingredient = \" \".join([lmtzr.lemmatize(x) for x in ingredient.split()])\n",
    "            cleaned_recipe.append(cleaned_ingredient)\n",
    "        cleaned_recipes.append(cleaned_recipe)\n",
    "    return cleaned_recipes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function above will strip individual words down to their lemmas and then convert them back to the same string primative they were joined to. For example, the recipe list: \n",
    "\n",
    "[['pepper', 'hot sauce', 'scallions', 'fresh parsley', 'green bell pepper', 'salt', 'wild rice', 'bay leaf', 'chicken', 'celery ribs', 'chopped fresh thyme', 'sauce', 'garlic cloves', 'onions', 'chicken stock', 'ground pork', 'butter oil', 'red bell pepper', 'long grain white rice'], \n",
    "\n",
    "['romaine lettuce', 'red wine vinegar', 'lemon juice', 'tomatoes', 'feta cheese', 'salt', 'gaeta olives', 'extra-virgin olive oil', 'oregano', 'mint', 'kirby cucumbers', 'freshly ground pepper'], \n",
    "\n",
    "['ground black pepper', 'italian eggplant', 'provolone cheese', 'marinara sauce', 'garlic', 'fresh basil leaves', 'herbs', 'extra-virgin olive oil', 'nonstick spray', 'coarse salt', 'parmagiano reggiano']]\n",
    "\n",
    "Yields: \n",
    "[['pepper', 'hot sauce', 'scallion', 'fresh parsley', 'green bell pepper', 'salt', 'wild rice', 'bay leaf', 'chicken', 'celery rib', 'chopped fresh thyme', 'sauce', 'garlic clove', 'onion', 'chicken stock', 'ground pork', 'butter oil', 'red bell pepper', 'long grain white rice'], \n",
    "\n",
    "['romaine lettuce', 'red wine vinegar', 'lemon juice', 'tomato', 'feta cheese', 'salt', 'gaeta olive', 'extra-virgin olive oil', 'oregano', 'mint', 'kirby cucumber', 'freshly ground pepper'], \n",
    "\n",
    "['ground black pepper', 'italian eggplant', 'provolone cheese', 'marinara sauce', 'garlic', 'fresh basil leaf', 'herb', 'extra-virgin olive oil', 'nonstick spray', 'coarse salt', 'parmagiano reggiano']]\n",
    "\n",
    "Notice that plural words (e.g., \"Scallions\", \"Cucumbers\") are reduced down to their root (scallion, cucumber) \n",
    "\n",
    "We can run the function on our dataset. Note that it'll run slowly as it's in O(n ** 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.74      0.54      0.62       115\n",
      "     british       0.59      0.38      0.46       194\n",
      "cajun_creole       0.81      0.68      0.74       371\n",
      "     chinese       0.80      0.81      0.81       677\n",
      "    filipino       0.68      0.57      0.62       174\n",
      "      french       0.62      0.60      0.61       657\n",
      "       greek       0.82      0.67      0.74       295\n",
      "      indian       0.84      0.89      0.86       780\n",
      "       irish       0.70      0.43      0.53       192\n",
      "     italian       0.77      0.89      0.83      1928\n",
      "    jamaican       0.79      0.60      0.68       129\n",
      "    japanese       0.80      0.67      0.73       373\n",
      "      korean       0.88      0.74      0.80       223\n",
      "     mexican       0.89      0.91      0.90      1625\n",
      "    moroccan       0.80      0.77      0.78       192\n",
      "     russian       0.65      0.37      0.47       116\n",
      " southern_us       0.66      0.82      0.73      1063\n",
      "     spanish       0.66      0.44      0.53       265\n",
      "        thai       0.75      0.74      0.74       353\n",
      "  vietnamese       0.70      0.51      0.59       222\n",
      "\n",
      " avg / total       0.77      0.77      0.76      9944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def fit_lemma_vectorizer(train, test):\n",
    "    \"\"\"Initalizes a count vectorizer with the words lemmatized \n",
    "    \"\"\"\n",
    "    count_vectorizer =  CountVectorizer(tokenizer = lambda doc: doc, \n",
    "                                       lowercase=False)\n",
    "    train_lemmas = prep_lemmatizer(train[\"ingredients\"])\n",
    "    test_lemmas = prep_lemmatizer(test[\"ingredients\"])\n",
    "    count_vectorizer.fit(train_lemmas)\n",
    "    train_matrix = count_vectorizer.transform(train_lemmas)\n",
    "    test_matrix = count_vectorizer.transform(test_lemmas)\n",
    "    return (train_matrix, train[\"cuisine\"]), (test_matrix, test[\"cuisine\"])  \n",
    "\n",
    "train_lemma, test_lemma = fit_lemma_vectorizer(train, test)\n",
    "lr_lemma = LogisticRegression().fit(train_lemma[0], train_lemma[1])\n",
    "lemma_predictions = lr_lemma.predict(test_lemma[0])\n",
    "lemma_report = report(test_lemma[1], lemma_predictions)\n",
    "print(lemma_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It looks like the lemmatization made some marginal improvements to our model. There are other preprocessing steps that we could pursue that may improve our predictions. For example, terms like \"extra-virgin oil\" probably do not differentiate a recipe any more than \"olive oil.\" We could spend more time on feature engineering to improve our predictions. \n",
    "\n",
    "For now, it might make sense to cover some of the algorithm choices that could improve our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('french', 'italian'), 140), (('italian', 'french'), 70), (('spanish', 'italian'), 64), (('cajun_creole', 'southern_us'), 63), (('french', 'southern_us'), 63), (('italian', 'southern_us'), 57), (('greek', 'italian'), 57), (('southern_us', 'italian'), 51), (('japanese', 'indian'), 46), (('british', 'southern_us'), 44)]\n"
     ]
    }
   ],
   "source": [
    "lemma_errors = [x for x in zip(test_lemma[1], lemma_predictions)]\n",
    "error_counter = Counter(lemma_errors)\n",
    "items_list = list(error_counter.items())\n",
    "true_errors = [x for x in items_list if x[0][0] != x[0][1]]\n",
    "true_errors.sort(key=lambda x: x[1], reverse=True)\n",
    "print(true_errors[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like this classifer performs poorly for the French-Italian pair compared. This may be be helpful in the future for when developing an ensemble model to predict the rest of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['romaine lettuce', 'black olive', 'grape tomato', 'garlic', 'pepper', 'purple onion', 'seasoning', 'garbanzo bean', 'feta cheese crumbles']\n"
     ]
    }
   ],
   "source": [
    "training_lemmas = prep_lemmatizer(raw_train[\"ingredients\"])\n",
    "print(training_lemmas[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# implement a voting classifier\n",
    "# in order to do this, you'll need to install the mlxtend library\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "count_vectorizer =  CountVectorizer(tokenizer = lambda doc: doc, \n",
    "                                       lowercase=False)\n",
    "\n",
    "\n",
    "count_vectorizer.fit(training_lemmas)\n",
    "train_matrix = count_vectorizer.transform(training_lemmas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72 (+/- 0.00) [Naive Bayes]\n",
      "Accuracy: 0.78 (+/- 0.00) [Logistic Regression]\n",
      "Accuracy: 0.76 (+/- 0.00) [SVM]\n",
      "Accuracy: 0.66 (+/- 0.00) [RandomForest]\n",
      "Accuracy: 0.78 (+/- 0.00) [ECLF]\n"
     ]
    }
   ],
   "source": [
    "clf1 = MultinomialNB()\n",
    "clf2 = LogisticRegression()\n",
    "clf3 = LinearSVC()\n",
    "clf4 = RandomForestClassifier()\n",
    "eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3, clf4], weights=[1, 1.5, 1, 1])\n",
    "labels = [\"Naive Bayes\", \"Logistic Regression\", \"SVM\", \"RandomForest\", \"ECLF\"]\n",
    "for clf, label in zip([clf1, clf2, clf3, clf4, eclf], labels):\n",
    "\n",
    "    scores = cross_val_score(clf, train_matrix, raw_train[\"cuisine\"], \n",
    "                                              cv=3, \n",
    "                                              scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" \n",
    "          % (scores.mean(), scores.std(), label))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try tuning the lexical features a bit more in order to improve our predictions. At first, we tried to preserve the structure of the data so that each multi-word ingredient was kept (e.g., feta cheese crumbles). It might make sense to consolidate everything into one string and test from there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "romaine lettuce black olive grape tomato garlic pepper purple onion seasoning garbanzo bean feta cheese crumbles\n"
     ]
    }
   ],
   "source": [
    "def flatten_lemma(ingredient_list):\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    new_ingredients = []\n",
    "    for item in ingredient_list:\n",
    "        plural = item.split()\n",
    "        new_ingredients.extend(plural)\n",
    "    return [lmtzr.lemmatize(x) for x in new_ingredients]\n",
    "# flatten everything into one string \n",
    "flat_data = [\" \".join(flatten_lemma(x)) for x in raw_train[\"ingredients\"]]\n",
    "print(flat_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try to improve our predictions by using a grid search to optimize the best hyper-parameters (e.g., the min number of words to consider, number of tokens, etc.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('tf_idf', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('NB', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'tf_idf__min_df': [1, 3, 10], 'tf_idf__ngram_range': [(1, 1), (1, 2)], 'tf_idf__max_df': [0.99, 0.85, 0.5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "le = LabelEncoder().fit(raw_train[\"cuisine\"])\n",
    "encoded_cuisine = le.transform(raw_train[\"cuisine\"]) \n",
    "params = {\"tf_idf__min_df\": [1, 3, 10], #min count of words allowed\n",
    "          \"tf_idf__ngram_range\": [(1, 1), (1, 2)], #ngram range to consider\n",
    "          \"tf_idf__max_df\": [.99, .85, .5] # max document frequency \n",
    "         } #1-grams or 2-grams\n",
    "\n",
    "estimators = [(\"tf_idf\", TfidfVectorizer()), \n",
    "              (\"SVC\", LinearSVC())]\n",
    "model = Pipeline(estimators)\n",
    "grid = GridSearchCV(estimator=model, param_grid = params)\n",
    "grid.fit(flat_data, encoded_cuisine) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tf_idf__max_df': 0.99, 'tf_idf__min_df': 1, 'tf_idf__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72 (+/- 0.00) [Naive Bayes]\n",
      "Accuracy: 0.78 (+/- 0.00) [Logistic Regression]\n",
      "Accuracy: 0.79 (+/- 0.00) [SVM]\n",
      "Accuracy: 0.70 (+/- 0.00) [RandomForest]\n",
      "Accuracy: 0.79 (+/- 0.00) [ECLF]\n"
     ]
    }
   ],
   "source": [
    "grouped_vectorizer = CountVectorizer()\n",
    "grouped_vectorizer.fit(flat_data)\n",
    "train_matrix2 = grouped_vectorizer.transform(flat_data)\n",
    "svc_estimators = [(\"tf_idf\", TfidfVectorizer()), \n",
    "                  (\"SVC\", LinearSVC())]\n",
    "nb_estimators = [(\"count_vectorizer\", CountVectorizer()), \n",
    "                  (\"SVC\", MultinomialNB())]\n",
    "logit_estimators = [(\"count_vectorizer\", CountVectorizer()), \n",
    "                  (\"LR\", LogisticRegression())]\n",
    "rf_estimators = [(\"count_vectorizer\", CountVectorizer()), \n",
    "                  (\"RF\", RandomForestClassifier())]\n",
    "\n",
    "clf1 = Pipeline(nb_estimators)\n",
    "clf2 = Pipeline(logit_estimators)\n",
    "clf3 = Pipeline(svc_estimators)\n",
    "clf4 = Pipeline(rf_estimators)\n",
    "eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3, clf4], weights=[1, 1, 1.5, .5])\n",
    "labels = [\"Naive Bayes\", \"Logistic Regression\", \"SVM\", \"RandomForest\", \"ECLF\"]\n",
    "for clf, label in zip([clf1, clf2, clf3, clf4, eclf], labels):\n",
    "\n",
    "    scores = cross_val_score(clf, flat_data, raw_train[\"cuisine\"], \n",
    "                                              cv=3, \n",
    "                                              scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" \n",
    "          % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This last model looks pretty good. We're getting ~ 79% accuracy and we haven't seen any major improvements with any of the feature or model tuning. To make a submission, we need to load in the test data and transform the features in the same way as the traning model. From there, we can make a prediction and a submission. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.json\", \"rb\") as t:\n",
    "    test_json = json.load(t)\n",
    "raw_test = pd.DataFrame.from_dict(test_json)\n",
    "flat_test = [\" \".join(flatten_lemma(x)) for x in raw_test[\"ingredients\"]]\n",
    "eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3, clf4], weights=[1, 1, 1.5, .5])\n",
    "eclf.fit(flat_data, raw_train[\"cuisine\"])\n",
    "test_predictions = eclf.predict(flat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame({\"id\":list(raw_test[\"id\"]), \"cuisine\":test_predictions})\n",
    "out_df.to_csv(\"RecipeOutput.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This submission scored .79022 when I uploaded it to Kaggle which would put it at ~400th place out of 1388. While we probably coud do better, this percentage was only ~ 2% of of the winning score. Depending on your application, a 2% improvement in modeling performance can be important or just noise. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
