{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from collections import Counter \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.metrics import classification_report as report \n",
    "from sklearn.model_selection import train_test_split as split, cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train = pd.read_csv(\"train.csv\")\n",
    "raw_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this process , however , afford me no mean of ascertain the dimension of my dungeon ; a i might make it circuit , and return to the point whence i set out , without be aware of the fact ; so perfectly uniform seem the wall .\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords, wordnet\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def wordnet_get(tagged_tokens):\n",
    "    \"\"\"Helper function for normalizing wordnet labels\n",
    "    \"\"\"\n",
    "    out_tokens = []\n",
    "    for token in tagged_tokens:\n",
    "        if token[1].startswith(\"J\"):\n",
    "            out_token = (token[0], wordnet.ADJ)\n",
    "        elif token[1].startswith(\"V\"):\n",
    "            out_token = (token[0], wordnet.VERB)\n",
    "        elif token[1].startswith(\"R\"):\n",
    "            out_token = (token[0], wordnet.ADV)\n",
    "        else:\n",
    "            out_token = (token[0], wordnet.NOUN)\n",
    "        out_tokens.append(out_token)\n",
    "    return out_tokens\n",
    "\n",
    "def clean_text(string, lemmatizer=lemmatizer):\n",
    "    \"\"\"Cleans the text by tokenizing, performing POS tagging, and lemmatizing it \n",
    "    \"\"\"\n",
    "    tokens = nltk.word_tokenize(string)\n",
    "    pos_tagged = wordnet_get(nltk.pos_tag(tokens))\n",
    "    lemmas = [lemmatizer.lemmatize(token[0], pos=token[1]).lower() for token in pos_tagged]\n",
    "    return lemmas\n",
    "\n",
    "\n",
    "min_clean = [\" \".join(clean_text(x)) for x in raw_train[\"text\"]]\n",
    "print(min_clean[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count_vec__binary': False, 'count_vec__max_df': 1.0, 'count_vec__ngram_range': (1, 2), 'count_vec__norm': None, 'count_vec__stop_words': None, 'count_vec__use_idf': True}\n"
     ]
    }
   ],
   "source": [
    "# try a simple Naive Bayes with just the minimal cleaning \n",
    "nb_params = { \n",
    "          \"count_vec__ngram_range\": [(1, 1), (1, 2), (1, 3)], \n",
    "          \"count_vec__max_df\": [1.0, .85, .5],\n",
    "          \"count_vec__stop_words\": [None, \"english\"],\n",
    "          \"count_vec__binary\": [True, False],\n",
    "          \"count_vec__norm\": [\"l1\", \"l2\", None],\n",
    "          \"count_vec__use_idf\": [False, True]} \n",
    "\n",
    "nb_estimators = [(\"count_vec\", TfidfVectorizer()), \n",
    "              (\"NB\", MultinomialNB())]\n",
    "nb_model = Pipeline(nb_estimators)\n",
    "nb_grid = GridSearchCV(estimator=nb_model, param_grid = nb_params)\n",
    "nb_grid.fit(min_clean, raw_train[\"author\"]) \n",
    "print(nb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84 (+/- 0.00) [Naive Bayes]\n"
     ]
    }
   ],
   "source": [
    "nb_estimators = [(\"count_vectorizer\", TfidfVectorizer(max_df=1.0, ngram_range=(1, 2), norm=None, stop_words=None)), \n",
    "                  (\"NB\", MultinomialNB())]\n",
    "clf1 = Pipeline(nb_estimators)\n",
    "scores = cross_val_score(clf1, min_clean, raw_train[\"author\"], \n",
    "                                              cv=3, \n",
    "                                              scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), \"Naive Bayes\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count_vec__binary': True, 'count_vec__ngram_range': (1, 2), 'count_vec__norm': None, 'count_vec__use_idf': True}\n"
     ]
    }
   ],
   "source": [
    "lr_params = { \n",
    "          \"count_vec__ngram_range\": [(1, 1), (1, 2)],\n",
    "          \"count_vec__binary\": [True, False],\n",
    "          \"count_vec__norm\": [None],\n",
    "          \"count_vec__use_idf\": [False, True]} \n",
    "\n",
    "lr_estimators = [(\"count_vec\", TfidfVectorizer()), \n",
    "              (\"LR\", LogisticRegression())]\n",
    "lr_model = Pipeline(lr_estimators)\n",
    "lr_grid = GridSearchCV(estimator=lr_model, param_grid = lr_params)\n",
    "lr_grid.fit(min_clean, raw_train[\"author\"]) \n",
    "print(lr_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82 (+/- 0.00) [Logistic Regression]\n"
     ]
    }
   ],
   "source": [
    "lr_estimators1 = [(\"count_vectorizer\", TfidfVectorizer(max_df=1.0, ngram_range=(1, 2), stop_words=None,\n",
    "                                                      binary=True, use_idf=True, norm=None)), \n",
    "                  (\"LR\", LogisticRegression())]\n",
    "clf2 = Pipeline(lr_estimators1)\n",
    "scores2 = cross_val_score(clf2, min_clean, raw_train[\"author\"], \n",
    "                                              cv=3, \n",
    "                                              scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores2.mean(), scores2.std(), \"Logistic Regression\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count_vec__binary': True, 'count_vec__ngram_range': (1, 2), 'count_vec__norm': None, 'count_vec__use_idf': True}\n"
     ]
    }
   ],
   "source": [
    "# Try an SVM with a Tfidf Matrix \n",
    "svm_params = { \n",
    "          \"count_vec__ngram_range\": [(1, 1), (1, 2)],\n",
    "          \"count_vec__binary\": [True, False],\n",
    "          \"count_vec__norm\": [None],\n",
    "          \"count_vec__use_idf\": [False, True]}\n",
    "\n",
    "svm_estimators = [(\"count_vec\", TfidfVectorizer()), \n",
    "              (\"SVM\", LinearSVC())]\n",
    "svm_model = Pipeline(svm_estimators)\n",
    "svm_grid = GridSearchCV(estimator=svm_model, param_grid = svm_params)\n",
    "svm_grid.fit(min_clean, raw_train[\"author\"]) \n",
    "print(svm_grid.best_params_)svm_estimators1 = [(\"count_vectorizer\", TfidfVectorizer(max_df=1.0, ngram_range=(1, 2), stop_words=None)), \n",
    "                  (\"SVM\", LinearSVC())]\n",
    "clf3 = Pipeline(svm_estimators1)\n",
    "scores3 = cross_val_score(clf3, min_clean, raw_train[\"author\"], \n",
    "                                              cv=3, \n",
    "                                              scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores3.mean(), scores3.std(), \"SVM\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.83 (+/- 0.01) [SVM]\n"
     ]
    }
   ],
   "source": [
    "svm_estimators1 = [(\"count_vectorizer\", TfidfVectorizer(max_df=1.0, ngram_range=(1, 2), stop_words=None)), \n",
    "                  (\"SVM\", LinearSVC())]\n",
    "clf3 = Pipeline(svm_estimators1 )\n",
    "scores3 = cross_val_score(clf3, min_clean, raw_train[\"author\"], \n",
    "                                              cv=3, \n",
    "                                              scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores3.mean(), scores3.std(), \"SVM\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT NN , RB , VBD PRP DT NNS IN VBG DT NNS IN PRP$ NN : IN PRP MD VB PRP$ NN , CC NN TO DT NN NN PRP VBP RP , IN VBG JJ IN DT NN : RB RB JJ VBD DT NN .\n"
     ]
    }
   ],
   "source": [
    "# try adding in the pos tags\n",
    "def get_pos(string):\n",
    "    tokens = nltk.word_tokenize(string)\n",
    "    pos_tagged = nltk.pos_tag(tokens)\n",
    "    return [x[1] for x in pos_tagged]\n",
    "\n",
    "\n",
    "pos_only = [\" \".join(get_pos(x)) for x in raw_train[\"text\"]]\n",
    "print(pos_only[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this process , however , afford me no mean of ascertain the dimension of my dungeon ; a i might make it circuit , and return to the point whence i set out , without be aware of the fact ; so perfectly uniform seem the wall . DT NN , RB , VBD PRP DT NNS IN VBG DT NNS IN PRP$ NN : IN PRP MD VB PRP$ NN , CC NN TO DT NN NN PRP VBP RP , IN VBG JJ IN DT NN : RB RB JJ VBD DT NN .\n"
     ]
    }
   ],
   "source": [
    "# pos_plus_words = [\" \".join(x[1], x[2]) for x in zip(min_clean, pos_only)]\n",
    "pos_plus_words = [\" \".join(x) for x in zip(min_clean, pos_only)]\n",
    "print(pos_plus_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count_vec__max_df': 0.5, 'count_vec__min_df': 1, 'count_vec__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "nb_params2 = {\"count_vec__min_df\": [1, 3, 10],\n",
    "              \"count_vec__use_idf\":[True, False]\n",
    "          \"count_vec__ngram_range\": [(1, 1), (1, 2), (1, 3), (3, 3)], \n",
    "          \"count_vec__max_df\": [1.0, .5]} \n",
    "\n",
    "nb_estimators2 = [(\"count_vec\", CountVectorizer()), \n",
    "              (\"NB\", MultinomialNB())]\n",
    "nb_model2 = Pipeline(nb_estimators2)\n",
    "nb_grid2 = GridSearchCV(estimator=nb_model2, param_grid = nb_params2)\n",
    "nb_grid2.fit(pos_plus_words, raw_train[\"author\"]) \n",
    "print(nb_grid2.best_params_)\n",
    "          \"count_vec__ngram_range\": [(1, 1), (1, 2), (1, 3), (3, 3)], \n",
    "          \"count_vec__max_df\": [1.0, .5]} \n",
    "\n",
    "nb_estimators2 = [(\"count_vec\", CountVectorizer()), \n",
    "              (\"NB\", MultinomialNB())]\n",
    "nb_model2 = Pipeline(nb_estimators2)\n",
    "nb_grid2 = GridSearchCV(estimator=nb_model2, param_grid = nb_params2)\n",
    "nb_grid2.fit(pos_plus_words, raw_train[\"author\"]) \n",
    "print(nb_grid2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.83 (+/- 0.00) [Naive Bayes]\n"
     ]
    }
   ],
   "source": [
    "# nb_2\n",
    "nb_estimators2 = [(\"count_vectorizer\", CountVectorizer(max_df=.5, ngram_range=(1, 1), stop_words=None)), \n",
    "                  (\"NB\", MultinomialNB())]\n",
    "clf4 = Pipeline(nb_estimators2)\n",
    "scores4 = cross_val_score(clf4, pos_plus_words, raw_train[\"author\"], \n",
    "                                              cv=3, \n",
    "                                              scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores4.mean(), scores4.std(), \"Naive Bayes\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.83 (+/- 0.00) [SVM]\n"
     ]
    }
   ],
   "source": [
    "svm_estimators2 = [(\"count_vectorizer\", TfidfVectorizer(max_df=1.0, ngram_range=(1, 2), stop_words=None)), \n",
    "                  (\"SVM\", LinearSVC())]\n",
    "clf5 = Pipeline(svm_estimators2)\n",
    "scores5 = cross_val_score(clf5, pos_plus_words, raw_train[\"author\"], \n",
    "                                              cv=3, \n",
    "                                              scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores5.mean(), scores5.std(), \"SVM\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count_vec__max_df': 1.0, 'count_vec__min_df': 1, 'count_vec__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "lr_params2 = {\"count_vec__min_df\": [1, 3, 10], \n",
    "          \"count_vec__ngram_range\": [(1, 1), (1, 2), (1, 3), (3, 3)], \n",
    "          \"count_vec__max_df\": [1.0, .75, .5]} \n",
    "\n",
    "lr_estimators2 = [(\"count_vec\", CountVectorizer()), \n",
    "              (\"LR\", LogisticRegression())]\n",
    "lr_model2 = Pipeline(lr_estimators2)\n",
    "lr_grid2 = GridSearchCV(estimator=lr_model2, param_grid = lr_params2)\n",
    "lr_grid2.fit(pos_plus_words, raw_train[\"author\"]) \n",
    "print(lr_grid2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.46 (+/- 0.00) [LR]\n"
     ]
    }
   ],
   "source": [
    "lr_estimators2 = [(\"count_vectorizer\", CountVectorizer(max_df=1, ngram_range=(1, 1), stop_words=None)), \n",
    "                  (\"LR\", LogisticRegression())]\n",
    "clf6 = Pipeline(lr_estimators2)\n",
    "scores6 = cross_val_score(clf6, pos_plus_words, raw_train[\"author\"], \n",
    "                                              cv=3, \n",
    "                                              scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores6.mean(), scores6.std(), \"LR\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count_vec__binary': False, 'count_vec__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "# Adaboost\n",
    "ada_params = { \n",
    "          \"count_vec__ngram_range\": [(1, 1), (1, 2)],\n",
    "          \"count_vec__binary\": [True, False]} \n",
    "\n",
    "ada_estimators = [(\"count_vec\", CountVectorizer()), \n",
    "              (\"Ada\", AdaBoostClassifier())]\n",
    "ada_model = Pipeline(ada_estimators)\n",
    "ada_grid = GridSearchCV(estimator=ada_model, param_grid = ada_params)\n",
    "ada_grid.fit(pos_plus_words, raw_train[\"author\"]) \n",
    "print(ada_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.60 (+/- 0.00) [Ada]\n"
     ]
    }
   ],
   "source": [
    "ada_estimators = [(\"count_vectorizer\", CountVectorizer(max_df=1.0, ngram_range=(1, 2), stop_words=None)), \n",
    "                  (\"Ada\", AdaBoostClassifier())]\n",
    "clf7 = Pipeline(ada_estimators)\n",
    "scores7 = cross_val_score(clf7, min_clean, raw_train[\"author\"], \n",
    "                                              cv=3, \n",
    "                                              scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores7.mean(), scores7.std(), \"Ada\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count_vec__binary': True, 'count_vec__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf_params = { \n",
    "          \"count_vec__ngram_range\": [(1, 1), (1, 2)],\n",
    "          \"count_vec__binary\": [True, False]} \n",
    "\n",
    "rf_estimators = [(\"count_vec\", CountVectorizer()), \n",
    "              (\"RF\", RandomForestClassifier())]\n",
    "rf_model = Pipeline(rf_estimators)\n",
    "rf_grid = GridSearchCV(estimator=rf_model, param_grid = rf_params)\n",
    "rf_grid.fit(pos_plus_words, raw_train[\"author\"]) \n",
    "print(rf_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.62 (+/- 0.01) [RF]\n"
     ]
    }
   ],
   "source": [
    "rf_estimators = [(\"count_vectorizer\", CountVectorizer(max_df=1.0, ngram_range=(1, 1), binary=True, stop_words=None)), \n",
    "                  (\"RF\", RandomForestClassifier())]\n",
    "clf8 = Pipeline(rf_estimators)\n",
    "scores8 = cross_val_score(clf8, min_clean, raw_train[\"author\"], \n",
    "                                              cv=3, \n",
    "                                              scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores8.mean(), scores8.std(), \"RF\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85 (+/- 0.00) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "clf4 = Pipeline(nb_estimators2)\n",
    "# training\n",
    "clf_batch_1 = [clf1, clf2, clf7, clf8, clf4]\n",
    "clf_batch_2 = [clf1, clf2, clf3]\n",
    "eclf = EnsembleVoteClassifier(clfs=clf_batch_1, weights=[1, 1, .5, .5, 1], voting=\"soft\")\n",
    "ensemble_scores = cross_val_score(eclf, min_clean, raw_train[\"author\"], \n",
    "                                              cv=3, \n",
    "                                              scoring='accuracy')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (ensemble_scores.mean(), ensemble_scores.std(), \"Ensemble\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnsembleVoteClassifier(clfs=[Pipeline(steps=[('count_vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), norm=None, preprocesso...nizer=None, vocabulary=None)), ('NB', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])],\n",
       "            refit=True, verbose=0, voting='hard',\n",
       "            weights=[1, 1, 1, 0.25, 0.25])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf = EnsembleVoteClassifier(clfs=clf_batch_1, weights=[1, 1, 1, .25, .25, 1])\n",
    "eclf.fit(min_clean, raw_train[\"author\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>Still, as I urged our leaving Ireland with suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>If a fire wanted fanning, it could readily be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00134</td>\n",
       "      <td>And when they had broken down the frail door t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27757</td>\n",
       "      <td>While I was thinking how I should possibly man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id04081</td>\n",
       "      <td>I am not sure to what limit his knowledge may ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text\n",
       "0  id02310  Still, as I urged our leaving Ireland with suc...\n",
       "1  id24541  If a fire wanted fanning, it could readily be ...\n",
       "2  id00134  And when they had broken down the frail door t...\n",
       "3  id27757  While I was thinking how I should possibly man...\n",
       "4  id04081  I am not sure to what limit his knowledge may ..."
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in test data\n",
    "raw_test = pd.read_csv(\"test.csv\")\n",
    "raw_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "still , a i urge our leave ireland with such inquietude and impatience , my father think it best to yield .\n"
     ]
    }
   ],
   "source": [
    "min_clean_test = [\" \".join(clean_text(x)) for x in raw_test[\"text\"]]\n",
    "print(min_clean_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MWS\n"
     ]
    }
   ],
   "source": [
    "predictions = eclf.predict(min_clean_test)\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.11357251  0.09375334  0.79267416]\n"
     ]
    }
   ],
   "source": [
    "output_pres = eclf.predict_proba(min_clean_test)\n",
    "print(output_pres[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
